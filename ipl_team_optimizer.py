# -*- coding: utf-8 -*-
"""ML_project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VPjTqbZ38GGYQ5ON2no1F4_2bLx5gQ2z

## Step 1: Loading Data and Initial Exploration

First, let's load the `matches.csv` and `deliveries.csv` files into pandas DataFrames. We'll also merge them to create a comprehensive dataset.
"""

import pandas as pd

# Load the datasets
matches = pd.read_csv('matches.csv')
deliveries = pd.read_csv('deliveries.csv')

# Merge the two dataframes for a combined view
# The 'id' column in matches corresponds to 'match_id' in deliveries
delivery_df = pd.merge(deliveries, matches, left_on='match_id', right_on='id')

print("Matches dataframe shape:", matches.shape)
print("Deliveries dataframe shape:", deliveries.shape)
print("Merged dataframe shape:", delivery_df.shape)

delivery_df.head()

"""## Step 2: Quantifying Player Performance

Now, we'll calculate key performance metrics for each player. We'll create separate statistics for batting and bowling.
"""

# Batting Performance Metrics

# Group by batter to calculate career stats
batsman_grp = delivery_df.groupby('batter')

# Total runs scored by each batsman
batsman_runs = batsman_grp['batsman_runs'].sum().reset_index()
batsman_runs.rename(columns={'batsman_runs': 'total_runs'}, inplace=True)

# Total balls faced by each batsman (excluding wides)
balls_faced = delivery_df[delivery_df['extras_type'] != 'wides'].groupby('batter')['ball'].count().reset_index()
balls_faced.rename(columns={'ball': 'balls_faced'}, inplace=True)

# Calculate Strike Rate
player_stats = pd.merge(batsman_runs, balls_faced, on='batter')
player_stats['strike_rate'] = (player_stats['total_runs'] / player_stats['balls_faced']) * 100

# Calculate Batting Average
dismissals = delivery_df[delivery_df['player_dismissed'].notna()].groupby('player_dismissed').size().reset_index(name='dismissals')
dismissals.rename(columns={'player_dismissed': 'batter'}, inplace=True)
player_stats = pd.merge(player_stats, dismissals, on='batter', how='left')

# --- FIX: Avoid inplace on a chained selection ---
player_stats['dismissals'] = player_stats['dismissals'].fillna(0)

player_stats['batting_average'] = player_stats['total_runs'] / (player_stats['dismissals']+1)
# Handle division by zero for players who have never been dismissed
# --- FIX: Avoid inplace on a chained selection ---
player_stats['batting_average'] = player_stats['batting_average'].fillna(0)


print("Batting Stats:")
player_stats.head()

# Bowling Performance Metrics

# Group by bowler to calculate career stats
bowler_grp = delivery_df.groupby('bowler')

# Total runs conceded by each bowler
runs_conceded = bowler_grp['total_runs'].sum().reset_index()
runs_conceded.rename(columns={'total_runs': 'runs_conceded'}, inplace=True)

# Total balls bowled by each bowler
balls_bowled = delivery_df.groupby('bowler')['ball'].count().reset_index()
balls_bowled.rename(columns={'ball': 'balls_bowled'}, inplace=True)

# Calculate Economy Rate
bowler_stats = pd.merge(runs_conceded, balls_bowled, on='bowler')
bowler_stats['economy_rate'] = (bowler_stats['runs_conceded'] / bowler_stats['balls_bowled']) * 6

# Total wickets taken
wickets_taken = delivery_df[delivery_df['dismissal_kind'].notna() & ~delivery_df['dismissal_kind'].isin(['run out', 'retired hurt', 'obstructing the field'])].groupby('bowler').size().reset_index(name='wickets')
bowler_stats = pd.merge(bowler_stats, wickets_taken, on='bowler', how='left')

# --- FIX: Avoid inplace on a chained selection ---
bowler_stats['wickets'] = bowler_stats['wickets'].fillna(0)

# Calculate Bowling Average
bowler_stats['bowling_average'] = bowler_stats['runs_conceded'] / (bowler_stats['wickets']+1)
# Handle division by zero for bowlers with no wickets
# --- FIX: Replace infinity with 0 after division ---
bowler_stats['bowling_average'] = bowler_stats['bowling_average'].replace([float('inf')], 0)


print("Bowling Stats:")
bowler_stats.head()

"""## Step 3: Context-Based Performance Analysis

Here, we'll analyze player performance against specific opposition teams and at different venues. This will allow us to create features that are sensitive to the match context.
"""

# Batting performance against a specific opposition
def get_batsman_vs_opposition_stats(batter_name, opposition_team, df):
    df_filtered = df[df['batter'] == batter_name]
    df_filtered = df_filtered[df_filtered['bowling_team'] == opposition_team]

    if df_filtered.empty:
        return None

    total_runs = df_filtered['batsman_runs'].sum()
    balls_faced = df_filtered[df_filtered['extras_type'] != 'wides'].shape[0]
    dismissals = df_filtered[df_filtered['player_dismissed'] == batter_name].shape[0]

    strike_rate = (total_runs / balls_faced) * 100 if balls_faced > 0 else 0
    batting_average = total_runs / dismissals if dismissals > 0 else total_runs

    return {'runs': total_runs, 'sr': strike_rate, 'avg': batting_average}

# Example: Virat Kohli vs Chennai Super Kings
kohli_vs_csk = get_batsman_vs_opposition_stats('V Kohli', 'Chennai Super Kings', delivery_df)
print(f"Virat Kohli vs CSK: {kohli_vs_csk}")

# Bowling performance against a specific opposition
def get_bowler_vs_opposition_stats(bowler_name, opposition_team, df):
    df_filtered = df[df['bowler'] == bowler_name]
    df_filtered = df_filtered[df_filtered['batting_team'] == opposition_team]

    if df_filtered.empty:
        return None

    runs_conceded = df_filtered['total_runs'].sum()
    balls_bowled = df_filtered.shape[0]
    wickets = df_filtered[df_filtered['dismissal_kind'].notna() & ~df_filtered['dismissal_kind'].isin(['run out', 'retired hurt', 'obstructing the field'])].shape[0]

    economy = (runs_conceded / balls_bowled) * 6 if balls_bowled > 0 else 0
    bowling_average = runs_conceded / wickets if wickets > 0 else runs_conceded

    return {'wickets': wickets, 'econ': economy, 'avg': bowling_average}

# Example: Jasprit Bumrah vs Kolkata Knight Riders
bumrah_vs_kkr = get_bowler_vs_opposition_stats('JJ Bumrah', 'Kolkata Knight Riders', delivery_df)
print(f"JJ Bumrah vs KKR: {bumrah_vs_kkr}")

"""These functions are useful for getting specific matchups. For our model, it will be more efficient to pre-calculate these stats for all players.

Let's create comprehensive dataframes for these context-based stats.
"""

# Pre-calculate all batsman-vs-opposition stats
batsman_vs_opposition = delivery_df.groupby(['batter', 'bowling_team']).agg(
    runs=('batsman_runs', 'sum'),
    balls=('ball', lambda x: delivery_df.loc[x.index][delivery_df.loc[x.index, 'extras_type'] != 'wides'].shape[0]),
    dismissals=('player_dismissed', lambda x: x.notna().sum())
).reset_index()

batsman_vs_opposition['strike_rate'] = (batsman_vs_opposition['runs'] / batsman_vs_opposition['balls']) * 100
batsman_vs_opposition['average'] = batsman_vs_opposition['runs'] / (batsman_vs_opposition['dismissals']+1)
batsman_vs_opposition.fillna({'average': 0, 'strike_rate': 0}, inplace=True)
batsman_vs_opposition['average'] = batsman_vs_opposition['average'].replace([float('inf')], 0)

print("Batsman vs Opposition Stats:")
batsman_vs_opposition.head()

import numpy as np

# Pre-calculate all bowler-vs-opposition stats

# This lambda returns the count of valid wicket types (exclude run out / retired hurt / obstructing the field)
bowler_vs_opposition = delivery_df.groupby(['bowler', 'batting_team']).agg(
    runs_conceded=('total_runs', 'sum'),
    balls_bowled=('ball', 'count'),
    wickets=('dismissal_kind', lambda x: (~x.isin(['run out', 'retired hurt', 'obstructing the field']) & x.notna()).sum())
).reset_index()

bowler_vs_opposition['economy'] = (bowler_vs_opposition['runs_conceded'] / bowler_vs_opposition['balls_bowled']) * 6

# Compute average safely (avoid division by zero)
bowler_vs_opposition['average'] = bowler_vs_opposition['runs_conceded'] / (bowler_vs_opposition['wickets']+1)

print("Bowler vs Opposition Stats:")
bowler_vs_opposition.head()

"""## Step 4: Defining Player Roles

To build a balanced team, we first need to classify players into roles like Batsman, Bowler, All-Rounder, and Wicketkeeper. We'll use their career stats to create these roles.
"""

# Merge overall batting and bowling stats
player_stats.rename(columns={'batter': 'player'}, inplace=True)
bowler_stats.rename(columns={'bowler': 'player'}, inplace=True)

players_df = pd.merge(player_stats, bowler_stats, on='player', how='outer')
players_df.fillna(0, inplace=True)

# Define roles based on heuristics
def get_player_role(player_row):
    balls_bowled = player_row['balls_bowled']
    balls_faced = player_row['balls_faced']

    # Heuristics: these thresholds can be tuned
    is_bowler = balls_bowled > 100
    is_batsman = balls_faced > 100

    if is_batsman and not is_bowler:
        return 'Batsman'
    if is_bowler and not is_batsman:
        return 'Bowler'
    if is_batsman and is_bowler:
        return 'All-Rounder'
    return 'Other' # Players with very little match time

players_df['role'] = players_df.apply(get_player_role, axis=1)

# Identify Wicketkeepers (based on stumping dismissals)
stumpings = delivery_df[delivery_df['dismissal_kind'] == 'stumped']['fielder'].value_counts().reset_index()
stumpings.rename(columns={'fielder': 'player', 'count': 'stumpings'}, inplace=True)
players_df = pd.merge(players_df, stumpings, on='player', how='left')
players_df['stumpings'] = players_df['stumpings'].fillna(0)

# A player with stumpings is likely a Wicketkeeper
players_df.loc[players_df['stumpings'] > 0, 'role'] = 'Wicketkeeper'

print("Player Roles Distribution:")
print(players_df['role'].value_counts())

players_df[['player', 'role', 'total_runs', 'balls_faced', 'wickets', 'balls_bowled']].head()

"""## Step 5: Building a Match Prediction Model

Now for the most critical part. We need to create a dataset where each row represents a match, with features describing the strengths of the two teams. Then we'll train a model to predict the winner.
"""

from tqdm import tqdm

def get_match_features(match, delivery_df, batsman_vs_opp, bowler_vs_opp):
    match_id = match['id']
    team1 = match['team1']
    team2 = match['team2']
    venue = match['venue']

    # Get players for this match
    match_deliveries = delivery_df[delivery_df['match_id'] == match_id]
    team1_players = match_deliveries[match_deliveries['batting_team'] == team1]['batter'].unique()
    team2_players = match_deliveries[match_deliveries['batting_team'] == team2]['batter'].unique()

    if len(team1_players) == 0 or len(team2_players) == 0:
        return None

    # Get team stats vs opposition
    team1_bat_stats = batsman_vs_opp[(batsman_vs_opp['batter'].isin(team1_players)) & (batsman_vs_opp['bowling_team'] == team2)]
    team2_bat_stats = batsman_vs_opp[(batsman_vs_opp['batter'].isin(team2_players)) & (batsman_vs_opp['bowling_team'] == team1)]

    team1_bowl_stats = bowler_vs_opp[(bowler_vs_opp['bowler'].isin(team1_players)) & (bowler_vs_opp['batting_team'] == team2)]
    team2_bowl_stats = bowler_vs_opp[(bowler_vs_opp['bowler'].isin(team2_players)) & (bowler_vs_opp['batting_team'] == team1)]

    features = {
        'team1_bat_avg': team1_bat_stats['average'].mean(),
        'team1_bat_sr': team1_bat_stats['strike_rate'].mean(),
        'team2_bat_avg': team2_bat_stats['average'].mean(),
        'team2_bat_sr': team2_bat_stats['strike_rate'].mean(),
        'team1_bowl_avg': team1_bowl_stats['average'].mean(),
        'team1_bowl_econ': team1_bowl_stats['economy'].mean(),
        'team2_bowl_avg': team2_bowl_stats['average'].mean(),
        'team2_bowl_econ': team2_bowl_stats['economy'].mean(),
        'toss_winner_is_team1': 1 if match['toss_winner'] == team1 else 0,
        'winner': 1 if match['winner'] == team1 else 0 # Target variable
    }

    return features

# Create the training data
training_data = []
for index, row in tqdm(matches.iterrows(), total=matches.shape[0], desc="Creating Match Features"):
    match_features = get_match_features(row, delivery_df, batsman_vs_opposition, bowler_vs_opposition)
    if match_features:
        training_data.append(match_features)

training_df = pd.DataFrame(training_data)
training_df.dropna(inplace=True)

print(f"Created training data with {training_df.shape[0]} matches.")
training_df.head()

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# Define features (X) and target (y)
X = training_df.drop('winner', axis=1)
y = training_df['winner']

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize and train the model
log_reg = LogisticRegression(max_iter=1000)
log_reg.fit(X_train, y_train)

# Evaluate the model
y_pred = log_reg.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

print(f"Match Prediction Model Accuracy: {accuracy:.2f}")

"""## Step 6: Optimal Playing XI Selection

This is the final step where we use our trained model to select the optimal playing XI. We'll use a greedy algorithm that iteratively builds a team by selecting players who provide the maximum increase in win probability, while respecting team composition constraints.
"""

import numpy as np

def calculate_win_prob(team1_players, team2_players, match_context):
    """Calculates the win probability for team1 based on the provided player lists."""
    team1 = match_context['team1']
    team2 = match_context['team2']

    # Get aggregated stats for the provided player lists
    team1_bat_stats = batsman_vs_opposition[(batsman_vs_opposition['batter'].isin(team1_players)) & (batsman_vs_opposition['bowling_team'] == team2)]
    team2_bat_stats = batsman_vs_opposition[(batsman_vs_opposition['batter'].isin(team2_players)) & (batsman_vs_opposition['bowling_team'] == team1)]
    team1_bowl_stats = bowler_vs_opposition[(bowler_vs_opposition['bowler'].isin(team1_players)) & (bowler_vs_opposition['batting_team'] == team2)]
    team2_bowl_stats = bowler_vs_opposition[(bowler_vs_opposition['bowler'].isin(team2_players)) & (bowler_vs_opposition['batting_team'] == team1)]

    # Create the feature vector for the model
    features = {
        'team1_bat_avg': team1_bat_stats['average'].mean(),
        'team1_bat_sr': team1_bat_stats['strike_rate'].mean(),
        'team2_bat_avg': team2_bat_stats['average'].mean(),
        'team2_bat_sr': team2_bat_stats['strike_rate'].mean(),
        'team1_bowl_avg': team1_bowl_stats['average'].mean(),
        'team1_bowl_econ': team1_bowl_stats['economy'].mean(),
        'team2_bowl_avg': team2_bowl_stats['average'].mean(),
        'team2_bowl_econ': team2_bowl_stats['economy'].mean(),
        'toss_winner_is_team1': match_context['toss_winner_is_team1']
    }

    # Convert to DataFrame, handle potential NaNs
    feature_df = pd.DataFrame([features])
    feature_df.fillna(0, inplace=True)

    # Predict probability
    win_prob = log_reg.predict_proba(feature_df)[0][1] # Probability of team1 winning
    return win_prob

def predict_optimal_xi(team1_squad, team2_squad, match_context):
    """Selects the best 11 players for team1 using a greedy approach."""

    # Define team composition constraints
    constraints = {'Wicketkeeper': 1, 'Batsman': 4, 'All-Rounder': 2, 'Bowler': 4}

    optimal_xi = []
    available_players = team1_squad.copy()

    # Start with a baseline opponent XI (e.g., their most experienced players)
    # For simplicity, we'll use the whole squad. A better approach might be to predict their XI too.
    opponent_xi = team2_squad

    # Iteratively build the team for 11 slots
    for i in range(11):
        best_player = None
        max_win_prob = -1

        # Get current role counts in the selected XI
        current_roles = pd.Series([players_df[players_df['player'] == p]['role'].values[0] for p in optimal_xi]).value_counts()

        for player in available_players:
            player_role = players_df[players_df['player'] == player]['role'].values[0]

            # Check if adding this player violates constraints
            if current_roles.get(player_role, 0) >= constraints.get(player_role, 0):
                continue

            # Temporarily add player and calculate new win probability
            temp_xi = optimal_xi + [player]
            win_prob = calculate_win_prob(temp_xi, opponent_xi, match_context)

            if win_prob > max_win_prob:
                max_win_prob = win_prob
                best_player = player

        if best_player:
            optimal_xi.append(best_player)
            available_players.remove(best_player)
        else:
            # If no player can be added due to constraints, break
            break

    return optimal_xi, max_win_prob

# --- Example Usage ---
# 1. Define the match context
team1 = 'Mumbai Indians'
team2 = 'Chennai Super Kings'
venue = 'Wankhede Stadium'

match_context = {
    'team1': team1,
    'team2': team2,
    'venue': venue,
    'toss_winner_is_team1': 1 # Assume team1 wins the toss
}

# 2. Define the player squads (full list of available players for each team)
# For this example, we'll get all players who have ever played for these teams
mi_players = delivery_df[delivery_df['batting_team'] == team1]['batter'].unique().tolist()
csk_players = delivery_df[delivery_df['batting_team'] == team2]['batter'].unique().tolist()

# 3. Predict the optimal XI
optimal_mi_xi, win_prob = predict_optimal_xi(mi_players, csk_players, match_context)

print(f"Optimal XI for {team1} against {team2}:")
for player in optimal_mi_xi:
    role = players_df[players_df['player'] == player]['role'].values[0]
    print(f"- {player} ({role})")

print(f"\nPredicted Win Probability: {win_prob:.2%}")

# ---- Additional imports for modeling & visualization ----
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,
                             roc_auc_score, roc_curve, confusion_matrix, classification_report)
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from collections import defaultdict

# XGBoost optional
try:
    from xgboost import XGBClassifier
    xgb_available = True
except Exception as e:
    XGBClassifier = None
    xgb_available = False
    print('xgboost not available, will skip XGBClassifier.')

# For imbalanced data handling (optional)
try:
    from imblearn.over_sampling import SMOTE
    imblearn_available = True
except Exception as e:
    SMOTE = None
    imblearn_available = False
    print('imblearn not available, will skip SMOTE oversampling.')

print('Libraries ready.')

# ---- Basic EDA & preprocessing visualizations ----
# We assume 'delivery_df' from original notebook is available and contains player and match info.
df = delivery_df.copy()
print('Data snapshot:')
display(df.head())

# Example of constructing a target: whether a player appears in final playing XI of a match
# The Kaggle IPL dataset uses 'player_dismissed' etc; however original notebook likely created features.
# We'll build a simple example target: for each match, the top 11 batsmen by 'batsman_runs' + bowlers by wickets
# NOTE: This is a heuristic placeholder — adapt to your original target if different.

# Aggregate runs and wickets by player per match
bats = df.groupby(['match_id','batter'])['batsman_runs'].sum().reset_index().rename(columns={'batter':'player','batsman_runs':'runs'})
wkts = df[df['player_dismissed'].notna()].groupby(['match_id','player_dismissed']).size().reset_index().rename(columns={'player_dismissed':'player',0:'wickets'})

agg = pd.merge(bats, wkts, how='left', on=['match_id','player']).fillna(0)
agg['impact'] = agg['runs'] + 20*agg['wickets']  # simple impact score
# For each match, mark top-11 impact players as 'selected'
agg['rank'] = agg.groupby('match_id')['impact'].rank(method='first', ascending=False)
agg['selected'] = (agg['rank'] <= 11).astype(int)

print('Constructed aggregated player-match table with target "selected".')
display(agg.head())

# Visualizations
plt.figure(figsize=(6,4))
sns.countplot(x='selected', data=agg)
plt.title('Distribution of constructed target: selected (1) vs not selected (0)')
plt.show()

# Numeric distribution examples
num_cols = ['runs','wickets','impact']
agg[num_cols].hist(bins=30, figsize=(12,4))
plt.suptitle('Histograms of numeric features')
plt.show()

# Correlation heatmap
plt.figure(figsize=(6,5))
sns.heatmap(agg[num_cols].corr(), annot=True, fmt='.2f')
plt.title('Correlation among numeric features')
plt.show()

# ---- Feature engineering, train/test split ----
# We'll create some simple features: runs, wickets, impact, recent form features (rolling in previous matches)
data = agg.copy()

# Example: previous match impact for the same player (lag feature)
data = data.sort_values(['player','match_id'])
data['prev_impact'] = data.groupby('player')['impact'].shift(1).fillna(0)

features = ['runs','wickets','impact','prev_impact']
X = data[features].fillna(0)
y = data['selected']

# Train-test split (grouped by match to avoid leakage) - we'll use a random split here for simplicity
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

print('Train shape:', X_train.shape, 'Test shape:', X_test.shape)

# Scaling
scaler = StandardScaler()
X_train_s = scaler.fit_transform(X_train)
X_test_s = scaler.transform(X_test)

# Optional SMOTE
if imblearn_available:
    sm = SMOTE(random_state=42)
    X_train_s, y_train = sm.fit_resample(X_train_s, y_train)
    print('After SMOTE, train shape:', X_train_s.shape, 'Train positive ratio:', y_train.mean())

# Models to evaluate
models = {
    'LogisticRegression': LogisticRegression(max_iter=1000),
    'RandomForest': RandomForestClassifier(n_estimators=200, random_state=42),
    'GradientBoosting': GradientBoostingClassifier(n_estimators=200, random_state=42),
    'SVC': SVC(probability=True, random_state=42)
}
if xgb_available:
    models['XGBoost'] = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)

results = {}
y_pred_proba = {}
for name, model in models.items():
    model.fit(X_train_s, y_train)
    y_pred = model.predict(X_test_s)
    # For ROC-AUC, need probabilities or decision_function
    if hasattr(model, 'predict_proba'):
        y_proba = model.predict_proba(X_test_s)[:,1]
    else:
        # fallback to decision_function scaled to 0-1 via ranking
        try:
            df = model.decision_function(X_test_s)
            # min-max scale to 0-1
            y_proba = (df - df.min()) / (df.max() - df.min())
        except:
            y_proba = np.zeros_like(y_pred, dtype=float)

    results[name] = {
        'accuracy': accuracy_score(y_test, y_pred),
        'precision': precision_score(y_test, y_pred, zero_division=0),
        'recall': recall_score(y_test, y_pred, zero_division=0),
        'f1': f1_score(y_test, y_pred, zero_division=0),
        'roc_auc': roc_auc_score(y_test, y_proba)
    }
    y_pred_proba[name] = (y_pred, y_proba)
    print(f"\nModel: {name}")
    print(classification_report(y_test, y_pred, zero_division=0))

# ---- Plot confusion matrices and ROC curves ----
plt.figure(figsize=(10,6))
accs = {k: v['accuracy'] for k,v in results.items()}
names = list(accs.keys())
vals = list(accs.values())
sns.barplot(x=vals, y=names)
plt.xlabel('Accuracy')
plt.title('Model accuracy comparison')
plt.xlim(0,1)
plt.show()

# Confusion matrices
for name, (y_pred, y_proba) in y_pred_proba.items():
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(4,3))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.title(f'Confusion matrix - {name}')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.show()

# ROC curves
plt.figure(figsize=(8,6))
for name, (y_pred, y_proba) in y_pred_proba.items():
    fpr, tpr, _ = roc_curve(y_test, y_proba)
    auc = results[name]['roc_auc']
    plt.plot(fpr, tpr, label=f"{name} (AUC={auc:.3f})")
plt.plot([0,1],[0,1],'--', linewidth=0.8)
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curves')
plt.legend()
plt.show()

# Show results table
res_df = pd.DataFrame(results).T.sort_values('f1', ascending=False)
display(res_df)

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# --- FIX: Re-load dataframes to ensure 'delivery_df' is defined in this execution context ---
# Load the datasets
matches = pd.read_csv('matches.csv')
deliveries = pd.read_csv('deliveries.csv')

# Merge the two dataframes for a combined view
# The 'id' column in matches corresponds to 'match_id' in deliveries
delivery_df = pd.merge(deliveries, matches, left_on='match_id', right_on='id')
# ----------------------------------------------------------------------------------------------

# ---- Basic EDA & preprocessing visualizations ----
# We assume 'delivery_df' from original notebook is available and contains player and match info.
df = delivery_df.copy()
print('Data snapshot:')
display(df.head())

# Example of constructing a target: whether a player appears in final playing XI of a match
# The Kaggle IPL dataset uses 'player_dismissed' etc; however original notebook likely created features.
# We'll build a simple example target: for each match, the top 11 batsmen by 'batsman_runs' + bowlers by wickets
# NOTE: This is a heuristic placeholder — adapt to your original target if different.

# Aggregate runs and wickets by player per match
bats = df.groupby(['match_id','batter'])['batsman_runs'].sum().reset_index().rename(columns={'batter':'player','batsman_runs':'runs'})
wkts = df[df['player_dismissed'].notna()].groupby(['match_id','player_dismissed']).size().reset_index().rename(columns={'player_dismissed':'player',0:'wickets'})

agg = pd.merge(bats, wkts, how='left', on=['match_id','player']).fillna(0)
agg['impact'] = agg['runs'] + 20*agg['wickets']  # simple impact score
# For each match, mark top-11 impact players as 'selected'
agg['rank'] = agg.groupby('match_id')['impact'].rank(method='first', ascending=False)
agg['selected'] = (agg['rank'] <= 11).astype(int)

print('Constructed aggregated player-match table with target "selected".')
display(agg.head())

# Visualizations

# 1. Countplot for 'selected' target variable
plt.figure(figsize=(6,4))
sns.countplot(x='selected', data=agg, palette='viridis')
plt.title('Distribution of Player Selection (Target Variable)', fontsize=14)
plt.xlabel('Player Selected (0 = No, 1 = Yes)', fontsize=12)
plt.ylabel('Number of Players', fontsize=12)
plt.xticks(ticks=[0, 1], labels=['Not Selected', 'Selected'])
plt.show()

# 2. Histograms of numeric features
num_cols = ['runs','wickets','impact']

plt.figure(figsize=(15, 5))
plt.suptitle('Histograms of Numeric Features', fontsize=16, y=1.02)

for i, col in enumerate(num_cols):
    plt.subplot(1, 3, i + 1)
    sns.histplot(agg[col], bins=30, kde=True, color=plt.cm.tab10(i))
    plt.title(f'Distribution of {col.replace("_", " ").title()}', fontsize=14)
    plt.xlabel(col.replace("_", " ").title(), fontsize=12)
    plt.ylabel('Frequency', fontsize=12)

plt.tight_layout()
plt.show()

# 3. Correlation heatmap
plt.figure(figsize=(7,6))
sns.heatmap(agg[num_cols].corr(), annot=True, fmt='.1f', cmap='coolwarm', linewidths=.5)
plt.title('Correlation Matrix of Numeric Features', fontsize=14)
plt.xticks(fontsize=10)
plt.yticks(fontsize=10, rotation=0)
plt.show()